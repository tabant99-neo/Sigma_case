import streamlit as st
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import tempfile
import os
import re
import numpy as np
from typing import List
import time

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É",
    page_icon="üá∑üá∫",
    layout="centered"
)

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ PyTorch –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
torch.set_num_threads(4)
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üá∑üá∫ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É")
st.markdown("""
–≠—Ç–æ –¥–µ–º–æ-–≤–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏, –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ DeepPavlov –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–∏—Å—å–º–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.
–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é.
""")

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤
class RussianExamGrader:
    def __init__(self, model_path, batch_size=32):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.batch_size = batch_size
        
        try:
            if not os.path.exists(model_path):
                st.error(f"‚ùå –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {model_path}")
                raise FileNotFoundError(f"Model path not found: {model_path}")
            
            st.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑: {model_path}")
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è GPU
            self.model.to(self.device)
            if self.device.type == 'cuda':
                self.model.half()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è GPU
                torch.backends.cudnn.benchmark = True
            
            self.model.eval()
            st.success("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            raise e

    def preprocess_text(self, text):
        """
        –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞.
        """
        text = str(text).lower()
        text = re.sub(r'[^\w\s]', '', text)
        return text

    def predict(self, text):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
        """
        try:
            processed_text = self.preprocess_text(text)
            inputs = self.tokenizer(
                processed_text,
                max_length=512,
                padding='max_length',
                truncation=True,
                return_tensors='pt'
            ).to(self.device)

            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPU
            if self.device.type == 'cuda':
                inputs = {k: v.half() if v.dtype == torch.float32 else v 
                         for k, v in inputs.items()}

            with torch.no_grad():
                outputs = self.model(**inputs)
                prediction = outputs.logits.cpu().numpy()

            grade = float(prediction[0][0])
            grade = max(0, min(5, grade))
            return round(grade, 2)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            return 0.0

    def predict_batch(self, texts: List[str]) -> List[float]:
        """
        –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        """
        try:
            processed_texts = [self.preprocess_text(text) for text in texts]
            
            # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            inputs = self.tokenizer(
                processed_texts,
                max_length=512,
                padding=True,  # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–∞–¥–¥–∏–Ω–≥ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                truncation=True,
                return_tensors='pt'
            ).to(self.device)
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPU
            if self.device.type == 'cuda':
                inputs = {k: v.half() if v.dtype == torch.float32 else v 
                         for k, v in inputs.items()}

            with torch.no_grad():
                outputs = self.model(**inputs)
                predictions = outputs.logits.cpu().numpy()

            grades = predictions[:, 0].tolist()
            grades = [max(0, min(5, float(grade))) for grade in grades]
            return [round(grade, 2) for grade in grades]
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –æ–¥–Ω–æ–º—É
            return [self.predict(text) for text in texts]

    def predict_large_dataset(self, texts: List[str], progress_callback=None) -> List[float]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Å –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π.
        """
        all_grades = []
        total_batches = (len(texts) + self.batch_size - 1) // self.batch_size
        
        for i in range(0, len(texts), self.batch_size):
            batch_texts = texts[i:i + self.batch_size]
            batch_grades = self.predict_batch(batch_texts)
            all_grades.extend(batch_grades)
            
            if progress_callback:
                progress_callback(i + len(batch_texts), len(texts))
        
        return all_grades

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è CSV
def safe_read_csv(uploaded_file):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ CSV —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏"""
    encodings = ['utf-8', 'cp1251', 'windows-1251', 'iso-8859-1']
    
    for encoding in encodings:
        try:
            uploaded_file.seek(0)
            for sep in [',', ';', '\t']:
                try:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, encoding=encoding, sep=sep)
                    if len(df.columns) > 0:
                        st.info(f"–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding} –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}'")
                        return df
                except:
                    continue
        except UnicodeDecodeError:
            continue
        except Exception as e:
            continue
    
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, sep='\t', encoding='utf-8')
        st.info("–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω –∫–∞–∫ TSV (—Ç–∞–±—É–ª—è—Ü–∏—è)")
        return df
    except:
        pass
    
    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —á—Ç–µ–Ω–∏–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='utf-8', on_bad_lines='skip')
        st.info("–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —Å –ø—Ä–æ–ø—É—Å–∫–æ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫")
        return df
    except:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –≤ UTF-8 —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –∑–∞–ø—è—Ç–∞—è.")

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV —Ñ–∞–π–ª–∞
def grade_csv_file_fast(df, grader, selected_column='answer'):
    """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ CSV —Ñ–∞–π–ª–∞ —Å –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    try:
        if selected_column not in df.columns:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü '{selected_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–∞–π–¥–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã: {list(df.columns)}")
            return None
        
        answers = df[selected_column].astype(str).tolist()
        
        # –°–æ–∑–¥–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        progress_bar = st.progress(0)
        status_text = st.empty()
        speed_text = st.empty()
        start_time = time.time()
        
        def update_progress(processed, total):
            progress = processed / total
            progress_bar.progress(progress)
            
            elapsed = time.time() - start_time
            if elapsed > 0:
                speed = processed / elapsed
                status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{total} –æ—Ç–≤–µ—Ç–æ–≤")
                speed_text.text(f"–°–∫–æ—Ä–æ—Å—Ç—å: {speed:.1f} –æ—Ç–≤–µ—Ç–æ–≤/—Å–µ–∫")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–∫–µ—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        st.info("üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–∫–æ—Ä–µ–Ω–Ω—É—é –ø–∞–∫–µ—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        grades = grader.predict_large_dataset(answers, progress_callback=update_progress)
        
        progress_bar.empty()
        status_text.empty()
        speed_text.empty()
        
        df['predicted_grade'] = grades
        
        total_time = time.time() - start_time
        st.success(f"‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(answers)} –æ—Ç–≤–µ—Ç–æ–≤ –∑–∞ {total_time:.1f} —Å–µ–∫")
        st.info(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {len(answers)/total_time:.1f} –æ—Ç–≤–µ—Ç–æ–≤/—Å–µ–∫")
        
        return df
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ CSV: {e}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ —á–∞—Å—Ç—è–º
def process_large_file_in_chunks(df, grader, selected_column, chunk_size=1000):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ —á–∞—Å—Ç—è–º"""
    total_rows = len(df)
    chunks = [df[i:i + chunk_size] for i in range(0, total_rows, chunk_size)]
    
    all_results = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, chunk in enumerate(chunks):
        status_text.text(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç—å {i+1}/{len(chunks)}...")
        
        chunk_result = grade_csv_file_fast(chunk, grader, selected_column)
        if chunk_result is not None:
            all_results.append(chunk_result)
        
        progress_bar.progress((i + 1) / len(chunks))
    
    progress_bar.empty()
    status_text.empty()
    
    if all_results:
        return pd.concat(all_results, ignore_index=True)
    return None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (–∫—ç—à–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∫–∞–∂–¥—ã–π —Ä–∞–∑)
@st.cache_resource
def load_grader():
    model_path = "my_trained_model_2"
    
    if not os.path.exists(model_path):
        absolute_path = "C:/Users/tkubanychbekov/Sigma_case/Sigma_case/my_trained_model_2"
        if os.path.exists(absolute_path):
            model_path = absolute_path
        else:
            st.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {model_path}")
            st.info("üîç –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, —á—Ç–æ –∏ app.py")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    return RussianExamGrader(model_path, batch_size=64)  # –£–≤–µ–ª–∏—á–∏–ª–∏ batch_size

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
try:
    grader = load_grader()
except Exception as e:
    st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
    st.info("""
    **–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:**
    1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ `my_trained_model_2` –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ, —á—Ç–æ –∏ `app.py`
    2. –ò–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –≤ –∫–æ–¥–µ (—Å—Ç—Ä–æ–∫–∞ 117)
    3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤ –ø–∞–ø–∫–µ –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª—ã: `pytorch_model.bin`, `config.json` –∏ –¥—Ä.
    """)
    st.stop()

# –°–æ–∑–¥–∞–µ–º –¥–≤–µ –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ –≤–≤–æ–¥–∞
tab1, tab2 = st.tabs(["üéØ –û—Ü–µ–Ω–∏—Ç—å –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç", "üìä –û—Ü–µ–Ω–∏—Ç—å —Ñ–∞–π–ª CSV"])

with tab1:
    st.header("–û—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
    user_input = st.text_area(
        "–í–≤–µ–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:",
        height=150,
        placeholder="–ù–∞–ø–∏—à–∏—Ç–µ –∑–¥–µ—Å—å –æ—Ç–≤–µ—Ç –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å...",
        key="single_answer"
    )

    if st.button("–û—Ü–µ–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç", type="primary", key="single"):
        if user_input.strip():
            with st.spinner("ü§ñ –ú–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç..."):
                start_time = time.time()
                grade = grader.predict(user_input)
                processing_time = time.time() - start_time
            
            st.success(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {grade} / 5**")
            st.info(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f} —Å–µ–∫")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
            col1, col2 = st.columns([1, 3])
            with col1:
                st.metric("–û—Ü–µ–Ω–∫–∞", f"{grade}/5")
            with col2:
                st.progress(grade / 5.0)
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
            if grade >= 4.5:
                st.info("üéâ –û—Ç–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç!")
            elif grade >= 3.5:
                st.info("üëç –•–æ—Ä–æ—à–∏–π –æ—Ç–≤–µ—Ç")
            elif grade >= 2.5:
                st.warning("‚ö†Ô∏è –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç")
            else:
                st.error("‚ùå –û—Ç–≤–µ—Ç —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π")
        else:
            st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏.")

with tab2:
    st.header("–ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏–∑ CSV-—Ñ–∞–π–ª–∞")
    st.markdown("""
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü —Å –æ—Ç–≤–µ—Ç–∞–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤.
    **–ù–æ–≤–∞—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 3-5 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ!** üöÄ
    """)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞
    with st.expander("üìã –ü—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ CSV-—Ñ–∞–π–ª–∞"):
        example_data = {
            'answer': [
                "–ú–æ—ë —Ö–æ–±–±–∏ - —á–∏—Ç–∞—Ç—å –∫–Ω–∏–≥–∏ –∏ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è —Å–ø–æ—Ä—Ç–æ–º.",
                "–Ø –ª—é–±–ª—é –ø—É—Ç–µ—à–µ—Å—Ç–≤–æ–≤–∞—Ç—å –∏ —É–∑–Ω–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ –∫—É–ª—å—Ç—É—Ä—ã.",
                "–í —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è —è –∏–∑—É—á–∞—é –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —è–∑—ã–∫–∏.",
                "–ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –ø—Ä–æ–≤–æ–¥–∏—Ç—å –≤—Ä–µ–º—è —Å —Å–µ–º—å—ë–π –∏ –¥—Ä—É–∑—å—è–º–∏.",
                "–Ø —É–≤–ª–µ–∫–∞—é—Å—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π –∏ –≤–∏–¥–µ–æ–º–æ–Ω—Ç–∞–∂–æ–º."
            ]
        }
        example_df = pd.DataFrame(example_data)
        st.dataframe(example_df)
        
        csv_example = example_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä CSV",
            data=csv_example,
            file_name="example_answers.csv",
            mime="text/csv",
            key="download_example"
        )
    
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ CSV-—Ñ–∞–π–ª", 
        type=['csv', 'txt'],
        key="file_uploader"
    )
    
    if uploaded_file is not None:
        try:
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
            df = safe_read_csv(uploaded_file)
            
            st.subheader("üìä –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            st.write(f"**–ù–∞–π–¥–µ–Ω–æ —Å—Ç–æ–ª–±—Ü–æ–≤:** {len(df.columns)}")
            st.write(f"**–ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫:** {len(df)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫
            st.dataframe(df.head())
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–æ–ª–±—Ü–∞—Ö
            with st.expander("üîç –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–æ–ª–±—Ü–∞—Ö"):
                for i, col in enumerate(df.columns):
                    st.write(f"**{i+1}. {col}** (—Ç–∏–ø: {df[col].dtype})")
                    if df[col].dtype == 'object':
                        sample_value = df[col].iloc[0] if len(df) > 0 else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                        st.write(f"   –ü—Ä–∏–º–µ—Ä: {str(sample_value)[:100]}...")
            
            st.subheader("üéØ –í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å –æ—Ç–≤–µ—Ç–∞–º–∏")
            if len(df.columns) > 0:
                selected_column = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–µ–∫—Å—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤:",
                    df.columns,
                    index=0,
                    key="column_selector"
                )
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
                st.write("**–ü—Ä–∏–º–µ—Ä –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞:**")
                sample_text = df[selected_column].iloc[0] if len(df) > 0 else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                st.text_area(
                    "–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞:",
                    value=str(sample_text)[:500],
                    height=100,
                    key="sample_text",
                    disabled=True
                )
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏"):
                    use_fast_processing = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É—Å–∫–æ—Ä–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É", value=True)
                    if len(df) > 5000:
                        use_chunking = st.checkbox("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –ø–æ —á–∞—Å—Ç—è–º", value=True)
                        chunk_size = st.slider("–†–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏", 1000, 10000, 2000)
                    else:
                        use_chunking = False
                
                if st.button("üöÄ –û—Ü–µ–Ω–∏—Ç—å –≤—Å–µ –æ—Ç–≤–µ—Ç—ã", type="primary", key="batch"):
                    with st.spinner("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è."):
                        start_time = time.time()
                        
                        if use_chunking and len(df) > 5000:
                            st.info(f"üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª –ø–æ —á–∞—Å—Ç—è–º ({chunk_size} —Å—Ç—Ä–æ–∫ –≤ —á–∞—Å—Ç–∏)")
                            result_df = process_large_file_in_chunks(df, grader, selected_column, chunk_size)
                        else:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                            if use_fast_processing:
                                result_df = grade_csv_file_fast(df, grader, selected_column)
                            else:
                                # –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                                st.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
                                answers = df[selected_column].astype(str).tolist()
                                
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                grades = []
                                total_answers = len(answers)
                                
                                for i, answer in enumerate(answers):
                                    grade = grader.predict(answer)
                                    grades.append(grade)
                                    
                                    progress = (i + 1) / total_answers
                                    progress_bar.progress(progress)
                                    status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i+1}/{total_answers} –æ—Ç–≤–µ—Ç–æ–≤")
                                
                                progress_bar.empty()
                                status_text.empty()
                                
                                result_df = df.copy()
                                result_df['predicted_grade'] = grades
                                
                                total_time = time.time() - start_time
                                st.success(f"‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_answers} –æ—Ç–≤–µ—Ç–æ–≤ –∑–∞ {total_time:.1f} —Å–µ–∫")
                        
                        if result_df is not None:
                            st.balloons()
                            st.subheader("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏")
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                            st.dataframe(result_df[[selected_column, 'predicted_grade']].head(10))
                            
                            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ü–µ–Ω–æ–∫
                            st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ü–µ–Ω–æ–∫")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                avg_grade = result_df['predicted_grade'].mean()
                                st.metric("–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", f"{avg_grade:.2f}")
                            with col2:
                                min_grade = result_df['predicted_grade'].min()
                                st.metric("–ú–∏–Ω. –æ—Ü–µ–Ω–∫–∞", f"{min_grade:.2f}")
                            with col3:
                                max_grade = result_df['predicted_grade'].max()
                                st.metric("–ú–∞–∫—Å. –æ—Ü–µ–Ω–∫–∞", f"{max_grade:.2f}")
                            with col4:
                                total_count = len(result_df)
                                st.metric("–í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤", total_count)
                            
                            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫
                            st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫")
                            grade_counts = result_df['predicted_grade'].value_counts().sort_index()
                            st.bar_chart(grade_counts)
                            
                            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                            
                            csv_result = result_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="üì• –°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV)",
                                data=csv_result,
                                file_name="graded_answers.csv",
                                mime="text/csv",
                                key="download_full"
                            )
                            
                        else:
                            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                        
            else:
                st.error("‚ùå –í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã –¥–∞–Ω–Ω—ã—Ö.")
                        
        except Exception as e:
            st.error(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            st.markdown("""
            **üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é –æ—à–∏–±–æ–∫:**
            - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV
            - –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π UTF-8
            - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å - –∑–∞–ø—è—Ç–∞—è
            - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤ —Ç–µ–∫—Å—Ç–∞—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–µ—Ç –ª–∏—à–Ω–∏—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫
            - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤
            """)

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
with st.sidebar:
    st.header("‚ÑπÔ∏è –û —Ä–µ—à–µ–Ω–∏–∏")
    st.markdown("""
    **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:**
    - **–ú–æ–¥–µ–ª—å**: DeepPavlov (–¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è)
    - **–ú–µ—Ç—Ä–∏–∫–∞**: MAE = 0.26
    - **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏**: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ
    - **–°–∫–æ—Ä–æ—Å—Ç—å**: –¥–æ 50+ –æ—Ç–≤–µ—Ç–æ–≤/—Å–µ–∫
    - **–®–∫–∞–ª–∞**: 0-5 –±–∞–ª–ª–æ–≤
    """)
    
    st.header("üìù –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è")
    st.markdown("""
    **–î–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏:**
    1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É "–û—Ü–µ–Ω–∏—Ç—å –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç"
    2. –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
    3. –ù–∞–∂–º–∏—Ç–µ "–û—Ü–µ–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç"
    
    **–î–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏:**
    1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É "–û—Ü–µ–Ω–∏—Ç—å —Ñ–∞–π–ª CSV"
    2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏
    3. –í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –æ—Ç–≤–µ—Ç–æ–≤
    4. –í–∫–ª—é—á–∏—Ç–µ "–£—Å–∫–æ—Ä–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É"
    5. –ù–∞–∂–º–∏—Ç–µ "–û—Ü–µ–Ω–∏—Ç—å –≤—Å–µ –æ—Ç–≤–µ—Ç—ã"
    6. –°–∫–∞—á–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    """)
    
    st.header("‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏")
    st.markdown("""
    - **–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** - –¥–æ 64 –æ—Ç–≤–µ—Ç–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
    - **GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CUDA
    - **–ü–æ–ª–æ–≤–∏–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ GPU
    - **–ß–∞–Ω–∫–æ–≤–∞–Ω–∏–µ** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ —á–∞—Å—Ç—è–º
    - **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ** - –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑
    """)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏
    st.header("üîß –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
    if 'grader' in locals():
        st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        st.info(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {grader.device}")
        st.info(f"üì¶ Batch size: {grader.batch_size}")
        if grader.device.type == 'cuda':
            st.success("üéØ GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ")
        else:
            st.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è GPU)")
    else:
        st.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown(
    "**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤** ‚Ä¢ "
    "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å DeepPavlov ‚Ä¢ "
    "MAE: 0.26 ‚Ä¢ "
    "‚ö° –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"
)
