import streamlit as st
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import os
import re
import numpy as np
from typing import List
import time

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É",
    page_icon="üá∑üá∫",
    layout="wide"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if 'processing_state' not in st.session_state:
    st.session_state.processing_state = {
        'is_processing': False,
        'total_rows': 0,
        'results': None,
        'selected_column': None
    }

if 'graded_results' not in st.session_state:
    st.session_state.graded_results = None

if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False

if 'grader_instance' not in st.session_state:
    st.session_state.grader_instance = None

if 'uploaded_data' not in st.session_state:
    st.session_state.uploaded_data = None

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üá∑üá∫ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É")
st.markdown("""
–≠—Ç–æ –¥–µ–º–æ-–≤–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏ –ø–∏—Å—å–º–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏.
""")

# –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∫–∞–∫ fallback
class SimpleRussianGrader:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def preprocess_text(self, text):
        text = str(text).strip()
        if not text:
            return ""
        return text

    def predict(self, text):
        try:
            if not text or len(str(text).strip()) == 0:
                return 0.0
                
            processed_text = self.preprocess_text(text)
            words = processed_text.split()
            
            if len(words) == 0:
                return 0.0
            
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
            length_score = min(len(words) / 50, 1.0)
            final_score = length_score * 5
            
            return round(final_score, 2)
            
        except Exception:
            return 0.0

    def predict_batch(self, texts: List[str]) -> List[float]:
        return [self.predict(text) for text in texts]

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
class RussianExamGrader:
    def __init__(self, model_path=None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        if model_path and os.path.exists(model_path):
            try:
                st.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑: {model_path}")
                self.tokenizer = AutoTokenizer.from_pretrained(model_path)
                self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
                self.model.to(self.device)
                self.model.eval()
                st.success("‚úÖ –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
                self.use_simple = False
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                st.warning("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å")
                self.use_simple = True
                self.simple_grader = SimpleRussianGrader()
        else:
            st.warning("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å")
            self.use_simple = True
            self.simple_grader = SimpleRussianGrader()

    def preprocess_text(self, text):
        text = str(text).strip()
        if not text:
            return ""
        return text

    def predict(self, text):
        if self.use_simple:
            return self.simple_grader.predict(text)
            
        try:
            if not text or len(str(text).strip()) == 0:
                return 0.0
                
            processed_text = self.preprocess_text(text)
            
            inputs = self.tokenizer(
                processed_text,
                max_length=512,
                padding='max_length',
                truncation=True,
                return_tensors='pt'
            ).to(self.device)

            with torch.no_grad():
                outputs = self.model(**inputs)
                prediction = outputs.logits.cpu().numpy()

            grade = float(prediction[0][0])
            grade = max(0, min(5, grade))
            return round(grade, 2)
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            return self.simple_grader.predict(text)

    def predict_batch(self, texts: List[str]) -> List[float]:
        if self.use_simple:
            return self.simple_grader.predict_batch(texts)
            
        try:
            processed_texts = [self.preprocess_text(text) for text in texts]
            
            inputs = self.tokenizer(
                processed_texts,
                max_length=512,
                padding=True,
                truncation=True,
                return_tensors='pt'
            ).to(self.device)

            with torch.no_grad():
                outputs = self.model(**inputs)
                predictions = outputs.logits.cpu().numpy()

            grades = predictions[:, 0].tolist()
            grades = [max(0, min(5, float(grade))) for grade in grades]
            return [round(grade, 2) for grade in grades]
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            return self.simple_grader.predict_batch(texts)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è CSV
def safe_read_csv(uploaded_file):
    """–ß—Ç–µ–Ω–∏–µ CSV —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –¥–ª—è UTF-8 –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è ';'"""
    try:
        # –ü—Ä–æ–±—É–µ–º UTF-8 —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ';'
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='utf-8', sep=';', on_bad_lines='skip')
        if len(df.columns) > 0 and len(df) > 0:
            st.success(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
            return df
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å UTF-8 –∏ ';': {e}")
    
    # –î—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='utf-8', sep=',', on_bad_lines='skip')
        if len(df.columns) > 0:
            st.info("–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ','")
            return df
    except:
        pass
        
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='cp1251', sep=';', on_bad_lines='skip')
        if len(df.columns) > 0:
            st.info("–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π cp1251")
            return df
    except:
        pass
    
    raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –≤—ã–±–æ—Ä–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞
def process_dataset_range(df, grader, selected_column, start_row, end_row, chunk_size=500):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
    try:
        if selected_column not in df.columns:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü '{selected_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–æ–∫
        selected_df = df.iloc[start_row:end_row].copy()
        total_rows = len(selected_df)
        
        st.info(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –¥–∏–∞–ø–∞–∑–æ–Ω: —Å—Ç—Ä–æ–∫–∏ {start_row}-{end_row} ({total_rows} —Å—Ç—Ä–æ–∫)")
        
        all_grades = []
        start_time = time.time()
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for start_idx in range(0, total_rows, chunk_size):
            if not st.session_state.processing_state['is_processing']:
                st.warning("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
                break
                
            chunk_end_idx = min(start_idx + chunk_size, total_rows)
            chunk = selected_df.iloc[start_idx:chunk_end_idx]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress = chunk_end_idx / total_rows
            progress_bar.progress(progress)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            elapsed = time.time() - start_time
            rows_per_sec = chunk_end_idx / elapsed if elapsed > 0 else 0
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {chunk_end_idx}/{total_rows} —Å—Ç—Ä–æ–∫ ({rows_per_sec:.1f} —Å—Ç—Ä–æ–∫/—Å–µ–∫)")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫
            answers = chunk[selected_column].astype(str).tolist()
            chunk_grades = grader.predict_batch(answers)
            all_grades.extend(chunk_grades)
        
        progress_bar.empty()
        status_text.empty()
        
        if len(all_grades) == total_rows:
            selected_df['predicted_grade'] = all_grades
            
            total_time = time.time() - start_time
            st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(all_grades)} –æ—Ç–≤–µ—Ç–æ–≤ –∑–∞ {total_time:.1f} —Å–µ–∫")
            
            return selected_df
        else:
            st.error(f"‚ùå –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–ª—å–∫–æ {len(all_grades)} –∏–∑ {total_rows} —Å—Ç—Ä–æ–∫")
            return None
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
        return None

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
def load_grader():
    model_path = "my_trained_model_2"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç–∏
    possible_paths = [
        model_path,
        f"./{model_path}",
        f"../{model_path}",
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return RussianExamGrader(path)
    
    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é
    st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é")
    return RussianExamGrader()

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
tab1, tab2, tab3 = st.tabs(["üéØ –û—Ü–µ–Ω–∏—Ç—å –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç", "üìä –û—Ü–µ–Ω–∏—Ç—å —Ñ–∞–π–ª CSV", "üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã"])

with tab1:
    st.header("–û—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
    
    if not st.session_state.model_loaded:
        if st.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"):
            with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å..."):
                grader = load_grader()
                st.session_state.grader_instance = grader
                st.session_state.model_loaded = True
                st.success("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞!")
                st.rerun()
    else:
        user_input = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:",
            height=150,
            placeholder="–ù–∞–ø–∏—à–∏—Ç–µ –∑–¥–µ—Å—å –æ—Ç–≤–µ—Ç –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å...",
            key="single_answer"
        )

        if st.button("–û—Ü–µ–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç", type="primary"):
            if user_input.strip():
                with st.spinner("ü§ñ –ú–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç..."):
                    grade = st.session_state.grader_instance.predict(user_input)
                
                st.success(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {grade} / 5**")
                
                col1, col2 = st.columns([1, 3])
                with col1:
                    st.metric("–û—Ü–µ–Ω–∫–∞", f"{grade}/5")
                with col2:
                    st.progress(grade / 5.0)
                
                if grade >= 4.0:
                    st.info("üéâ –û—Ç–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç!")
                elif grade >= 3.0:
                    st.info("üëç –•–æ—Ä–æ—à–∏–π –æ—Ç–≤–µ—Ç")
                elif grade >= 2.0:
                    st.warning("‚ö†Ô∏è –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç")
                else:
                    st.error("‚ùå –û—Ç–≤–µ—Ç —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π")
            else:
                st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏.")

with tab2:
    st.header("–ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏–∑ CSV-—Ñ–∞–π–ª–∞")
    
    if st.session_state.processing_state['is_processing']:
        st.warning("üîÑ –ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞...")
        if st.button("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É"):
            st.session_state.processing_state['is_processing'] = False
            st.rerun()
    
    st.markdown("""
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤. **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç:** UTF-8 —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ';'
    """)
    
    if not st.session_state.model_loaded:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–û—Ü–µ–Ω–∏—Ç—å –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç'")
    else:
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV-—Ñ–∞–π–ª", type=['csv'])
        
        if uploaded_file is not None:
            if st.session_state.uploaded_data is None:
                with st.spinner("üìñ –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª..."):
                    df = safe_read_csv(uploaded_file)
                    st.session_state.uploaded_data = df
            else:
                df = st.session_state.uploaded_data
            
            st.subheader("üìä –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            st.write(f"**–†–∞–∑–º–µ—Ä:** {len(df)} —Å—Ç—Ä–æ–∫ √ó {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
            with st.expander("üëÄ –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∞–Ω–Ω—ã–µ"):
                st.dataframe(df.head(10))
            
            st.subheader("üéØ –í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å –æ—Ç–≤–µ—Ç–∞–º–∏")
            selected_column = st.selectbox("–°—Ç–æ–ª–±–µ—Ü —Å –æ—Ç–≤–µ—Ç–∞–º–∏:", df.columns, index=0)
            
            st.subheader("üìã –í—ã–±–æ—Ä –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏")
            
            col1, col2 = st.columns(2)
            with col1:
                start_row = st.number_input(
                    "–ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞:",
                    min_value=0,
                    max_value=len(df)-1,
                    value=0,
                    help="–ù—É–º–µ—Ä–∞—Ü–∏—è —Å 0"
                )
            with col2:
                end_row = st.number_input(
                    "–ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞:",
                    min_value=1,
                    max_value=len(df),
                    value=min(1000, len(df)),
                    help="–ù–µ –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ (–∫–∞–∫ –≤ Python slicing)"
                )
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
            if start_row < end_row:
                selected_range_df = df.iloc[start_row:end_row]
                st.info(f"**–í—ã–±—Ä–∞–Ω –¥–∏–∞–ø–∞–∑–æ–Ω:** —Å—Ç—Ä–æ–∫–∏ {start_row}-{end_row} ({len(selected_range_df)} —Å—Ç—Ä–æ–∫)")
                
                with st.expander("üëÄ –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏"):
                    st.dataframe(selected_range_df.head(10))
                
                # –ë—ã—Å—Ç—Ä—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
                st.subheader("‚ö° –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä")
                quick_col1, quick_col2, quick_col3, quick_col4 = st.columns(4)
                
                with quick_col1:
                    if st.button("–ü–µ—Ä–≤—ã–µ 100", use_container_width=True):
                        st.session_state.start_row = 0
                        st.session_state.end_row = 100
                        st.rerun()
                with quick_col2:
                    if st.button("–ü–µ—Ä–≤—ã–µ 1000", use_container_width=True):
                        st.session_state.start_row = 0
                        st.session_state.end_row = 1000
                        st.rerun()
                with quick_col3:
                    if st.button("–ü–æ—Å–ª–µ–¥–Ω–∏–µ 100", use_container_width=True):
                        st.session_state.start_row = max(0, len(df) - 100)
                        st.session_state.end_row = len(df)
                        st.rerun()
                with quick_col4:
                    if st.button("–í—Å–µ —Å—Ç—Ä–æ–∫–∏", use_container_width=True):
                        st.session_state.start_row = 0
                        st.session_state.end_row = len(df)
                        st.rerun()
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                chunk_size = st.slider("–†–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏:", 100, 1000, 500, 100)
                
                if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ—Ü–µ–Ω–∫—É –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞", type="primary"):
                    if not st.session_state.processing_state['is_processing']:
                        st.session_state.processing_state['is_processing'] = True
                        
                        result_df = process_dataset_range(
                            df, 
                            st.session_state.grader_instance, 
                            selected_column, 
                            start_row, 
                            end_row, 
                            chunk_size
                        )
                        
                        st.session_state.processing_state['is_processing'] = False
                        
                        if result_df is not None:
                            st.session_state.graded_results = result_df
                            st.session_state.processing_state['selected_column'] = selected_column
                            st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–æ—Ç–æ–≤—ã! –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã'")
            else:
                st.error("‚ùå –ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –º–µ–Ω—å—à–µ –∫–æ–Ω–µ—á–Ω–æ–π")

with tab3:
    st.header("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏")
    
    if st.session_state.graded_results is not None:
        result_df = st.session_state.graded_results
        
        st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(result_df)}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ü–µ–Ω–æ–∫")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            avg_grade = result_df['predicted_grade'].mean()
            st.metric("–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", f"{avg_grade:.2f}")
        with col2:
            min_grade = result_df['predicted_grade'].min()
            st.metric("–ú–∏–Ω. –æ—Ü–µ–Ω–∫–∞", f"{min_grade:.2f}")
        with col3:
            max_grade = result_df['predicted_grade'].max()
            st.metric("–ú–∞–∫—Å. –æ—Ü–µ–Ω–∫–∞", f"{max_grade:.2f}")
        with col4:
            st.metric("–í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤", len(result_df))
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫")
        grade_counts = result_df['predicted_grade'].value_counts().sort_index()
        st.bar_chart(grade_counts)
        
        # –¢–∞–±–ª–∏—Ü–∞
        st.subheader("üìã –î–µ—Ç–∞–ª–∏ –æ—Ü–µ–Ω–æ–∫")
        selected_column = st.session_state.processing_state.get('selected_column', 'answer')
        
        page_size = st.slider("–°—Ç—Ä–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ:", 10, 100, 20)
        page = st.number_input("–°—Ç—Ä–∞–Ω–∏—Ü–∞:", min_value=1, value=1)
        
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        
        st.dataframe(
            result_df.iloc[start_idx:end_idx][[selected_column, 'predicted_grade']],
            height=400
        )
        
        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
        st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        csv_data = result_df.to_csv(index=False, sep=';').encode('utf-8')
        st.download_button(
            label=f"üì• –°–∫–∞—á–∞—Ç—å ({len(result_df)} —Å—Ç—Ä–æ–∫)",
            data=csv_data,
            file_name="graded_answers.csv",
            mime="text/csv"
        )
        
    else:
        st.info("‚ÑπÔ∏è –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—è–≤—è—Ç—Å—è –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞")

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    st.header("‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ")
    st.markdown("""
    **–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞:**
    - CSV —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π UTF-8
    - –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: ;
    - –°—Ç–æ–ª–±–µ—Ü —Å —Ç–µ–∫—Å—Ç–æ–º –æ—Ç–≤–µ—Ç–æ–≤
    """)
    
    st.header("üìä –°—Ç–∞—Ç—É—Å")
    if st.session_state.model_loaded:
        st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    else:
        st.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    if st.session_state.uploaded_data is not None:
        st.info(f"üìÅ –§–∞–π–ª: {len(st.session_state.uploaded_data)} —Å—Ç—Ä–æ–∫")
    
    if st.session_state.processing_state['is_processing']:
        st.warning("üîÑ –ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞")
    else:
        st.success("‚úÖ –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")

st.markdown("---")
st.markdown("**–°–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤** ‚Ä¢ –í—ã–±–æ—Ä –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Å—Ç—Ä–æ–∫ ‚Ä¢ UTF-8 —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ';'")
