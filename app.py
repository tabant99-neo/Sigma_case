import streamlit as st
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import tempfile
import os
import re
import numpy as np
from typing import List
import time
import gc

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É",
    page_icon="üá∑üá∫",
    layout="wide"
)

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ PyTorch –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
torch.set_num_threads(4)
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
if 'processing_state' not in st.session_state:
    st.session_state.processing_state = {
        'is_processing': False,
        'current_index': 0,
        'total_rows': 0,
        'start_time': 0,
        'results': None,
        'original_df': None,
        'selected_column': None
    }

if 'graded_results' not in st.session_state:
    st.session_state.graded_results = None

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üá∑üá∫ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É")
st.markdown("""
–≠—Ç–æ –¥–µ–º–æ-–≤–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏ –ø–∏—Å—å–º–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é.
""")

# –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
class SimpleRussianGrader:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
        self.quality_indicators = {
            'length_weight': 0.2,
            'vocabulary_weight': 0.3,
            'structure_weight': 0.3,
            'grammar_weight': 0.2
        }
        
        # –ü—Ä–∏–º–µ—Ä—ã —Ö–æ—Ä–æ—à–∏—Ö —Ñ—Ä–∞–∑ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        self.good_phrases = [
            '–º–Ω–µ –∫–∞–∂–µ—Ç—Å—è', '–ø–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é', '—Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã', '—Å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã',
            '—Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º', '–≤ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ', '–≤–æ-–ø–µ—Ä–≤—ã—Ö', '–≤–æ-–≤—Ç–æ—Ä—ã—Ö', '–≤-—Ç—Ä–µ—Ç—å–∏—Ö',
            '–∫—Ä–æ–º–µ —Ç–æ–≥–æ', '–Ω–∞–ø—Ä–∏–º–µ—Ä', '—Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º', '—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ', '–æ–¥–Ω–∞–∫–æ',
            '–ø–æ—ç—Ç–æ–º—É', '–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ', '–≤ —Ü–µ–ª–æ–º', '–ø–æ–¥–≤–æ–¥—è –∏—Ç–æ–≥'
        ]

    def preprocess_text(self, text):
        """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞."""
        text = str(text).lower().strip()
        if not text:
            return ""
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text

    def analyze_text_quality(self, text):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é —ç–≤—Ä–∏—Å—Ç–∏–∫."""
        if not text or len(str(text).strip()) == 0:
            return 0.0
            
        text = self.preprocess_text(text)
        words = text.split()
        
        if len(words) == 0:
            return 0.0
        
        # 1. –û—Ü–µ–Ω–∫–∞ –ø–æ –¥–ª–∏–Ω–µ
        length_score = min(len(words) / 30, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 30 —Å–ª–æ–≤–∞–º
        
        # 2. –û—Ü–µ–Ω–∫–∞ –ø–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—é –ª–µ–∫—Å–∏–∫–∏
        unique_words = len(set(words))
        vocab_score = min(unique_words / max(len(words), 1) * 2, 1.0)
        
        # 3. –û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ä–æ—à–∏—Ö —Ñ—Ä–∞–∑)
        structure_score = 0
        for phrase in self.good_phrases:
            if phrase in text:
                structure_score += 0.05
        structure_score = min(structure_score, 1.0)
        
        # 4. –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤)
        short_words = sum(1 for word in words if len(word) <= 2)
        grammar_score = 1.0 - min(short_words / max(len(words), 1) * 1.5, 1.0)
        
        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        final_score = (
            length_score * self.quality_indicators['length_weight'] +
            vocab_score * self.quality_indicators['vocabulary_weight'] +
            structure_score * self.quality_indicators['structure_weight'] +
            grammar_score * self.quality_indicators['grammar_weight']
        )
        
        return min(final_score * 5, 5.0)  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–æ 5 –±–∞–ª–ª–æ–≤

    def predict(self, text):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        try:
            return round(self.analyze_text_quality(text), 2)
        except Exception:
            return 0.0

    def predict_batch(self, texts: List[str]) -> List[float]:
        """–ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        return [self.predict(text) for text in texts]

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
class RussianExamGrader:
    def __init__(self):
        self.simple_grader = SimpleRussianGrader()
        st.success("‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")

    def predict(self, text):
        return self.simple_grader.predict(text)

    def predict_batch(self, texts: List[str]) -> List[float]:
        return self.simple_grader.predict_batch(texts)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è CSV
def safe_read_csv(uploaded_file):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ CSV —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏"""
    encodings = ['utf-8', 'cp1251', 'windows-1251', 'iso-8859-1', 'latin1']
    
    for encoding in encodings:
        try:
            uploaded_file.seek(0)
            for sep in [',', ';', '\t']:
                try:
                    uploaded_file.seek(0)
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º chunksize –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    chunks = []
                    for chunk in pd.read_csv(uploaded_file, encoding=encoding, sep=sep, chunksize=10000):
                        chunks.append(chunk)
                    
                    if chunks:
                        df = pd.concat(chunks, ignore_index=True)
                        if len(df.columns) > 0 and len(df) > 0:
                            st.success(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
                            st.info(f"–ö–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding}, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: '{sep}'")
                            return df
                except Exception as e:
                    continue
        except UnicodeDecodeError:
            continue
        except Exception as e:
            continue
    
    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding='utf-8', on_bad_lines='skip', engine='python')
        if len(df) > 0:
            st.info("–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —Å –ø—Ä–æ–ø—É—Å–∫–æ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫")
            return df
    except:
        pass
    
    raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª")

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö CSV —Ñ–∞–π–ª–æ–≤
def process_large_dataset(df, grader, selected_column, chunk_size=1000):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –ø–æ —á–∞—Å—Ç—è–º —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
    try:
        if selected_column not in df.columns:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü '{selected_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        total_rows = len(df)
        st.info(f"üìä –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_rows} —Å—Ç—Ä–æ–∫")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –¥–ª—è UI
        progress_container = st.container()
        status_container = st.container()
        stats_container = st.container()
        
        all_grades = []
        processed_rows = 0
        start_time = time.time()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª –ø–æ —á–∞—Å—Ç—è–º
        for start_idx in range(0, total_rows, chunk_size):
            if not st.session_state.processing_state['is_processing']:
                st.warning("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
                break
                
            end_idx = min(start_idx + chunk_size, total_rows)
            chunk = df.iloc[start_idx:end_idx]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º UI
            with progress_container:
                progress = end_idx / total_rows
                st.progress(progress)
            
            with status_container:
                elapsed = time.time() - start_time
                rows_per_sec = end_idx / elapsed if elapsed > 0 else 0
                remaining_time = (total_rows - end_idx) / rows_per_sec if rows_per_sec > 0 else 0
                
                st.write(f"""
                **–ü—Ä–æ–≥—Ä–µ—Å—Å:** {end_idx}/{total_rows} —Å—Ç—Ä–æ–∫ ({progress:.1%})
                **–°–∫–æ—Ä–æ—Å—Ç—å:** {rows_per_sec:.1f} —Å—Ç—Ä–æ–∫/—Å–µ–∫
                **–û—Å—Ç–∞–ª–æ—Å—å:** {remaining_time:.0f} —Å–µ–∫
                **–¢–µ–∫—É—â–∞—è —á–∞—Å—Ç—å:** {start_idx}-{end_idx}
                """)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å
            answers = chunk[selected_column].astype(str).tolist()
            chunk_grades = grader.predict_batch(answers)
            all_grades.extend(chunk_grades)
            
            processed_rows = end_idx
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            with stats_container:
                if len(all_grades) > 0:
                    current_avg = np.mean(all_grades)
                    current_min = min(all_grades)
                    current_max = max(all_grades)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", f"{current_avg:.2f}")
                    with col2:
                        st.metric("–ú–∏–Ω. –æ—Ü–µ–Ω–∫–∞", f"{current_min:.2f}")
                    with col3:
                        st.metric("–ú–∞–∫—Å. –æ—Ü–µ–Ω–∫–∞", f"{current_max:.2f}")
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            st.rerun()
        
        # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        st.session_state.processing_state['is_processing'] = False
        
        if len(all_grades) == total_rows:
            result_df = df.copy()
            result_df['predicted_grade'] = all_grades
            
            total_time = time.time() - start_time
            st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(all_grades)} –æ—Ç–≤–µ—Ç–æ–≤ –∑–∞ {total_time:.1f} —Å–µ–∫")
            st.info(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {len(all_grades)/total_time:.1f} –æ—Ç–≤–µ—Ç–æ–≤/—Å–µ–∫")
            
            return result_df
        else:
            st.error(f"‚ùå –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–ª—å–∫–æ {len(all_grades)} –∏–∑ {total_rows} —Å—Ç—Ä–æ–∫")
            return None
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
        st.session_state.processing_state['is_processing'] = False
        return None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_grader():
    return RussianExamGrader()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
try:
    grader = load_grader()
except Exception as e:
    st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏: {e}")
    st.stop()

# –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏
tab1, tab2, tab3 = st.tabs(["üéØ –û—Ü–µ–Ω–∏—Ç—å –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç", "üìä –û—Ü–µ–Ω–∏—Ç—å —Ñ–∞–π–ª CSV", "üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã"])

with tab1:
    st.header("–û—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
    user_input = st.text_area(
        "–í–≤–µ–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:",
        height=150,
        placeholder="–ù–∞–ø–∏—à–∏—Ç–µ –∑–¥–µ—Å—å –æ—Ç–≤–µ—Ç –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å...",
        key="single_answer"
    )

    if st.button("–û—Ü–µ–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç", type="primary", key="single"):
        if user_input.strip():
            with st.spinner("ü§ñ –ú–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç..."):
                start_time = time.time()
                grade = grader.predict(user_input)
                processing_time = time.time() - start_time
            
            st.success(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {grade} / 5**")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
            col1, col2 = st.columns([1, 3])
            with col1:
                st.metric("–û—Ü–µ–Ω–∫–∞", f"{grade}/5")
            with col2:
                st.progress(grade / 5.0)
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
            if grade >= 4.0:
                st.info("üéâ –û—Ç–ª–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç!")
            elif grade >= 3.0:
                st.info("üëç –•–æ—Ä–æ—à–∏–π –æ—Ç–≤–µ—Ç")
            elif grade >= 2.0:
                st.warning("‚ö†Ô∏è –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç")
            else:
                st.error("‚ùå –û—Ç–≤–µ—Ç —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π")
        else:
            st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏.")

with tab2:
    st.header("–ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏–∑ CSV-—Ñ–∞–π–ª–∞")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å —Ç–µ–∫—É—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if st.session_state.processing_state['is_processing']:
        st.warning("üîÑ –ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞...")
        if st.button("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É"):
            st.session_state.processing_state['is_processing'] = False
            st.rerun()
    
    st.markdown("""
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–∞–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã (10,000+ —Å—Ç—Ä–æ–∫).
    """)
    
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ CSV-—Ñ–∞–π–ª", 
        type=['csv'],
        key="file_uploader"
    )
    
    if uploaded_file is not None and not st.session_state.processing_state['is_processing']:
        try:
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            with st.spinner("üìñ –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª..."):
                df = safe_read_csv(uploaded_file)
            
            st.subheader("üìä –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            st.write(f"**–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** {len(df)} —Å—Ç—Ä–æ–∫ √ó {len(df.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö
            col1, col2 = st.columns(2)
            with col1:
                st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", len(df))
            with col2:
                st.metric("–í—Å–µ–≥–æ —Å—Ç–æ–ª–±—Ü–æ–≤", len(df.columns))
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
            with st.expander("üëÄ –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫"):
                st.dataframe(df.head(10))
            
            # –í—ã–±–æ—Ä —Å—Ç–æ–ª–±—Ü–∞ —Å –æ—Ç–≤–µ—Ç–∞–º–∏
            st.subheader("üéØ –í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å –æ—Ç–≤–µ—Ç–∞–º–∏")
            selected_column = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–µ–∫—Å—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤:",
                df.columns,
                index=0
            )
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            chunk_size = st.slider(
                "–†–∞–∑–º–µ—Ä —á–∞—Å—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:",
                min_value=500,
                max_value=5000,
                value=1000,
                step=500,
                help="–ú–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—é—Ç –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏, –Ω–æ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–¥–ª–µ–Ω–Ω–µ–µ"
            )
            
            if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ—Ü–µ–Ω–∫—É –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤", type="primary"):
                if len(df) > 10000:
                    st.warning(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª ({len(df)} —Å—Ç—Ä–æ–∫). –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                st.session_state.processing_state.update({
                    'is_processing': True,
                    'total_rows': len(df),
                    'original_df': df,
                    'selected_column': selected_column
                })
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                result_df = process_large_dataset(df, grader, selected_column, chunk_size)
                
                if result_df is not None:
                    st.session_state.graded_results = result_df
                    st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–æ—Ç–æ–≤—ã! –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã'")
                    st.rerun()
                        
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —Ñ–∞–π–ª–æ–º: {e}")

with tab3:
    st.header("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏")
    
    if st.session_state.graded_results is not None:
        result_df = st.session_state.graded_results
        
        st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(result_df)}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ü–µ–Ω–æ–∫")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            avg_grade = result_df['predicted_grade'].mean()
            st.metric("–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", f"{avg_grade:.2f}")
        with col2:
            min_grade = result_df['predicted_grade'].min()
            st.metric("–ú–∏–Ω. –æ—Ü–µ–Ω–∫–∞", f"{min_grade:.2f}")
        with col3:
            max_grade = result_df['predicted_grade'].max()
            st.metric("–ú–∞–∫—Å. –æ—Ü–µ–Ω–∫–∞", f"{max_grade:.2f}")
        with col4:
            st.metric("–í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤", len(result_df))
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫
        st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫")
        
        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
        grade_bins = pd.cut(result_df['predicted_grade'], 
                           bins=[0, 1, 2, 3, 4, 5], 
                           labels=['0-1', '1-2', '2-3', '3-4', '4-5'])
        grade_distribution = grade_bins.value_counts().sort_index()
        st.bar_chart(grade_distribution)
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        st.subheader("üìã –î–µ—Ç–∞–ª–∏ –æ—Ü–µ–Ω–æ–∫")
        
        # –ü–æ–∏—Å–∫ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        search_col1, search_col2 = st.columns(2)
        with search_col1:
            min_filter = st.slider("–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞", 0.0, 5.0, 0.0, 0.5)
        with search_col2:
            max_filter = st.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞", 0.0, 5.0, 5.0, 0.5)
        
        filtered_df = result_df[
            (result_df['predicted_grade'] >= min_filter) & 
            (result_df['predicted_grade'] <= max_filter)
        ]
        
        st.write(f"**–ù–∞–π–¥–µ–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤:** {len(filtered_df)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        page_size = 100
        total_pages = max(1, len(filtered_df) // page_size)
        
        page = st.number_input("–°—Ç—Ä–∞–Ω–∏—Ü–∞", min_value=1, max_value=total_pages, value=1)
        
        start_idx = (page - 1) * page_size
        end_idx = min(start_idx + page_size, len(filtered_df))
        
        st.dataframe(
            filtered_df.iloc[start_idx:end_idx][
                [st.session_state.processing_state['selected_column'], 'predicted_grade']
            ],
            height=400
        )
        
        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        
        csv_data = result_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label=f"üì• –°–∫–∞—á–∞—Ç—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ({len(result_df)} —Å—Ç—Ä–æ–∫)",
            data=csv_data,
            file_name=f"graded_answers_{len(result_df)}_rows.csv",
            mime="text/csv"
        )
        
    else:
        st.info("‚ÑπÔ∏è –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –ø–æ—è–≤—è—Ç—Å—è –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞")

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    st.header("‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ")
    st.markdown("""
    **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
    - –û—Ü–µ–Ω–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    - –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ CSV
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """)
    
    st.header("üìä –°—Ç–∞—Ç—É—Å")
    if st.session_state.processing_state['is_processing']:
        st.warning("–ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞")
        progress = st.session_state.processing_state.get('current_index', 0) / max(1, st.session_state.processing_state.get('total_rows', 1))
        st.progress(progress)
    else:
        st.success("–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
    
    if st.session_state.graded_results is not None:
        st.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(st.session_state.graded_results)} –æ—Ç–≤–µ—Ç–æ–≤")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown("**–°–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤** ‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤")
